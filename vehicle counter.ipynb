{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Webcam successfully opened.\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 1\n",
      "Number of cars detected: 2\n",
      "Number of cars detected: 2\n",
      "Number of cars detected: 1\n",
      "Number of cars detected: 2\n",
      "Number of cars detected: 2\n",
      "Number of cars detected: 5\n",
      "Number of cars detected: 5\n",
      "Number of cars detected: 3\n",
      "Number of cars detected: 3\n",
      "Number of cars detected: 4\n",
      "Number of cars detected: 4\n",
      "Number of cars detected: 3\n",
      "Number of cars detected: 4\n",
      "Number of cars detected: 5\n",
      "Number of cars detected: 5\n",
      "Number of cars detected: 5\n",
      "Number of cars detected: 5\n",
      "Number of cars detected: 4\n",
      "Number of cars detected: 8\n",
      "Number of cars detected: 8\n",
      "Number of cars detected: 8\n",
      "Number of cars detected: 8\n",
      "Number of cars detected: 8\n",
      "Number of cars detected: 5\n",
      "Number of cars detected: 4\n",
      "Number of cars detected: 4\n",
      "Number of cars detected: 4\n",
      "Number of cars detected: 5\n",
      "Number of cars detected: 6\n",
      "Number of cars detected: 5\n",
      "Number of cars detected: 5\n",
      "Number of cars detected: 5\n",
      "Number of cars detected: 4\n",
      "Number of cars detected: 5\n",
      "Number of cars detected: 4\n",
      "Number of cars detected: 3\n",
      "Number of cars detected: 6\n",
      "Number of cars detected: 5\n",
      "Number of cars detected: 3\n",
      "Number of cars detected: 3\n",
      "Number of cars detected: 1\n",
      "Number of cars detected: 1\n",
      "Number of cars detected: 4\n",
      "Number of cars detected: 3\n",
      "Number of cars detected: 2\n",
      "Number of cars detected: 3\n",
      "Number of cars detected: 2\n",
      "Number of cars detected: 3\n",
      "Number of cars detected: 3\n",
      "Number of cars detected: 1\n",
      "Number of cars detected: 2\n",
      "Number of cars detected: 2\n",
      "Number of cars detected: 2\n",
      "Number of cars detected: 3\n",
      "Number of cars detected: 2\n",
      "Number of cars detected: 2\n",
      "Number of cars detected: 3\n",
      "Number of cars detected: 3\n",
      "Number of cars detected: 5\n",
      "Number of cars detected: 6\n",
      "Number of cars detected: 5\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 2\n",
      "Number of cars detected: 3\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n",
      "Number of cars detected: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 91\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Process the current frame\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m processed_frame \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Display the processed frame\u001b[39;00m\n\u001b[0;32m     94\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWebcam\u001b[39m\u001b[38;5;124m\"\u001b[39m, processed_frame)\n",
      "Cell \u001b[1;32mIn[1], line 33\u001b[0m, in \u001b[0;36mprocess_frame\u001b[1;34m(frame)\u001b[0m\n\u001b[0;32m     31\u001b[0m blob \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mdnn\u001b[38;5;241m.\u001b[39mblobFromImage(frame, \u001b[38;5;241m0.00392\u001b[39m, (\u001b[38;5;241m416\u001b[39m, \u001b[38;5;241m416\u001b[39m), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;28;01mTrue\u001b[39;00m, crop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     32\u001b[0m net\u001b[38;5;241m.\u001b[39msetInput(blob)\n\u001b[1;32m---> 33\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Initialize variables for detected class IDs, confidences, and bounding boxes\u001b[39;00m\n\u001b[0;32m     36\u001b[0m class_ids \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Paths to the YOLOv3 files\n",
    "weights_path = r\"D:\\python\\python_INSTALL\\myenv\\darknet\\src\\yolov3.weights\"\n",
    "config_path = r\"D:\\python\\python_INSTALL\\myenv\\darknet\\cfg\\yolov3.cfg\"\n",
    "names_path = r\"D:\\python\\python_INSTALL\\myenv\\darknet\\data\\coco.names\"\n",
    "\n",
    "# Ensure the paths exist\n",
    "if not (os.path.exists(weights_path) and os.path.exists(config_path) and os.path.exists(names_path)):\n",
    "    print(\"Error: One or more paths to YOLOv3 files are incorrect.\")\n",
    "    exit()\n",
    "\n",
    "# Load YOLOv3 configuration and weights\n",
    "net = cv2.dnn.readNet(weights_path, config_path)\n",
    "\n",
    "# Load the COCO class labels YOLO was trained on\n",
    "with open(names_path, \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Get the output layer names of the YOLO network\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Function to process a single frame\n",
    "def process_frame(frame):\n",
    "    height, width, channels = frame.shape\n",
    "\n",
    "    # Prepare the frame for YOLO\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    # Initialize variables for detected class IDs, confidences, and bounding boxes\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    # Process YOLO outputs\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5 and class_id == 2:  # 2 is the class ID for 'car' in COCO dataset\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    # Apply non-maxima suppression to filter overlapping boxes\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "    # Draw bounding boxes on the frame\n",
    "    car_count = 0\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            color = (0, 255, 0)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(frame, label, (x, y - 10), font, 1, color, 2)\n",
    "            car_count += 1\n",
    "\n",
    "    print(f\"Number of cars detected: {car_count}\")\n",
    "    return frame\n",
    "\n",
    "# Access the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Webcam successfully opened.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame.\")\n",
    "        break\n",
    "\n",
    "    # Process the current frame\n",
    "    processed_frame = process_frame(frame)\n",
    "\n",
    "    # Display the processed frame\n",
    "    cv2.imshow(\"Webcam\", processed_frame)\n",
    "\n",
    "    # Exit when 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Webcam successfully opened.\n",
      "Number of cars detected: 1\n",
      "Number of cars detected: 3\n",
      "Number of cars detected: 4\n",
      "Number of cars detected: 3\n",
      "Number of cars detected: 3\n",
      "Number of cars detected: 4\n",
      "Number of cars detected: 4\n",
      "Number of cars detected: 5\n",
      "Number of cars detected: 4\n",
      "Number of cars detected: 5\n",
      "Number of cars detected: 5\n",
      "Number of cars detected: 4\n",
      "Number of cars detected: 5\n",
      "Number of cars detected: 4\n",
      "Number of cars detected: 5\n",
      "Number of cars detected: 4\n",
      "Number of cars detected: 4\n",
      "Number of cars detected: 5\n",
      "Number of cars detected: 4\n",
      "Number of cars detected: 4\n",
      "Detection duration ended.\n",
      "Total number of cars detected in 10 seconds: 80\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from config import DETECTION_DURATION  # Importing the duration from config.py\n",
    "\n",
    "# Paths to the YOLOv3 files\n",
    "weights_path = r\"D:\\python\\python_INSTALL\\myenv\\darknet\\src\\yolov3.weights\"\n",
    "config_path = r\"D:\\python\\python_INSTALL\\myenv\\darknet\\cfg\\yolov3.cfg\"\n",
    "names_path = r\"D:\\python\\python_INSTALL\\myenv\\darknet\\data\\coco.names\"\n",
    "\n",
    "# Ensure the paths exist\n",
    "if not (os.path.exists(weights_path) and os.path.exists(config_path) and os.path.exists(names_path)):\n",
    "    print(\"Error: One or more paths to YOLOv3 files are incorrect.\")\n",
    "    exit()\n",
    "\n",
    "# Load YOLOv3 configuration and weights\n",
    "net = cv2.dnn.readNet(weights_path, config_path)\n",
    "\n",
    "# Load the COCO class labels YOLO was trained on\n",
    "with open(names_path, \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Get the output layer names of the YOLO network\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Function to process a single frame\n",
    "def process_frame(frame):\n",
    "    height, width, channels = frame.shape\n",
    "\n",
    "    # Prepare the frame for YOLO\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    # Initialize variables for detected class IDs, confidences, and bounding boxes\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    # Process YOLO outputs\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5 and class_id == 2:  # 2 is the class ID for 'car' in COCO dataset\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    # Apply non-maxima suppression to filter overlapping boxes\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "    # Draw bounding boxes on the frame\n",
    "    car_count = 0\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            color = (0, 255, 0)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(frame, label, (x, y - 10), font, 1, color, 2)\n",
    "            car_count += 1\n",
    "\n",
    "    print(f\"Number of cars detected: {car_count}\")\n",
    "    return frame, car_count\n",
    "\n",
    "# Access the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Webcam successfully opened.\")\n",
    "\n",
    "start_time = time.time()  # Record the start time\n",
    "total_car_count = 0  # Initialize total car count\n",
    "\n",
    "while True:\n",
    "    elapsed_time = time.time() - start_time\n",
    "    if elapsed_time > DETECTION_DURATION:\n",
    "        print(\"Detection duration ended.\")\n",
    "        break\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame.\")\n",
    "        break\n",
    "\n",
    "    # Process the current frame\n",
    "    processed_frame, car_count = process_frame(frame)\n",
    "    total_car_count += car_count  # Accumulate car count\n",
    "\n",
    "    # Display the processed frame\n",
    "    cv2.imshow(\"Webcam\", processed_frame)\n",
    "\n",
    "    # Exit when 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "print(f\"Total number of cars detected in {DETECTION_DURATION} seconds: {total_car_count}\")\n",
    "\n",
    "# Release the webcam and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Webcam successfully opened.\n",
      "Waiting for 10 seconds before starting detection...\n",
      "Detection period ended.\n",
      "Number of cars detected in the last 5 seconds: 8\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from config import DETECTION_DURATION  # Importing the duration from config.py\n",
    "\n",
    "# Paths to the YOLOv3 files\n",
    "weights_path = r\"D:\\python\\python_INSTALL\\myenv\\darknet\\src\\yolov3.weights\"\n",
    "config_path = r\"D:\\python\\python_INSTALL\\myenv\\darknet\\cfg\\yolov3.cfg\"\n",
    "names_path = r\"D:\\python\\python_INSTALL\\myenv\\darknet\\data\\coco.names\"\n",
    "\n",
    "# Ensure the paths exist\n",
    "if not (os.path.exists(weights_path) and os.path.exists(config_path) and os.path.exists(names_path)):\n",
    "    print(\"Error: One or more paths to YOLOv3 files are incorrect.\")\n",
    "    exit()\n",
    "\n",
    "# Load YOLOv3 configuration and weights\n",
    "net = cv2.dnn.readNet(weights_path, config_path)\n",
    "\n",
    "# Load the COCO class labels YOLO was trained on\n",
    "with open(names_path, \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Get the output layer names of the YOLO network\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Function to process a single frame\n",
    "def process_frame(frame):\n",
    "    height, width, channels = frame.shape\n",
    "\n",
    "    # Prepare the frame for YOLO\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    # Initialize variables for detected class IDs, confidences, and bounding boxes\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    # Process YOLO outputs\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5 and class_id == 2:  # 2 is the class ID for 'car' in COCO dataset\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    # Apply non-maxima suppression to filter overlapping boxes\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "    # Draw bounding boxes on the frame\n",
    "    car_count = 0\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            color = (0, 255, 0)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(frame, label, (x, y - 10), font, 1, color, 2)\n",
    "            car_count += 1\n",
    "\n",
    "    return frame, car_count\n",
    "\n",
    "# Access the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Webcam successfully opened.\")\n",
    "\n",
    "# Wait for the specified detection duration before starting detection\n",
    "print(f\"Waiting for {DETECTION_DURATION} seconds before starting detection...\")\n",
    "time.sleep(DETECTION_DURATION)\n",
    "\n",
    "start_time = time.time()  # Record the start time of the detection period\n",
    "detection_time = 5  # Time to detect cars after the waiting period\n",
    "end_time = start_time + detection_time  # Calculate the end time of the detection period\n",
    "\n",
    "total_car_count = 0  # Initialize total car count\n",
    "\n",
    "while True:\n",
    "    current_time = time.time()\n",
    "    elapsed_time = current_time - start_time\n",
    "\n",
    "    if elapsed_time > detection_time:\n",
    "        print(\"Detection period ended.\")\n",
    "        break\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame.\")\n",
    "        break\n",
    "\n",
    "    # Process the current frame\n",
    "    processed_frame, car_count = process_frame(frame)\n",
    "    total_car_count = car_count  # Update car count for the current frame\n",
    "\n",
    "    # Display the processed frame\n",
    "    cv2.imshow(\"Webcam\", processed_frame)\n",
    "\n",
    "    # Exit when 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "print(f\"Number of cars detected in the last {detection_time} seconds: {total_car_count}\")\n",
    "\n",
    "# Release the webcam and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Webcam successfully opened.\n",
      "Waiting for 10 seconds before starting detection...\n",
      "Detection period ended.\n",
      "Number of cars detected in the last 5 seconds: 10\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 3)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32md:\\python\\python_INSTALL\\myenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3577\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn[13], line 126\u001b[0m\n    config_data = ast.literal_eval(config_data)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mD:\\python\\python_INSTALL\\Lib\\ast.py:66\u001b[0m in \u001b[0;35mliteral_eval\u001b[0m\n    node_or_string = parse(node_or_string.lstrip(\" \\t\"), mode='eval')\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32mD:\\python\\python_INSTALL\\Lib\\ast.py:52\u001b[1;36m in \u001b[1;35mparse\u001b[1;36m\n\u001b[1;33m    return compile(source, filename, mode, flags,\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32m<unknown>:3\u001b[1;36m\u001b[0m\n\u001b[1;33m    DETECTION_DURATION = 10  # Example duration in seconds\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import config  # Import the config module\n",
    "import ast\n",
    "\n",
    "# Paths to the YOLOv3 files\n",
    "weights_path = r\"D:\\python\\python_INSTALL\\myenv\\darknet\\src\\yolov3.weights\"\n",
    "config_path = r\"D:\\python\\python_INSTALL\\myenv\\darknet\\cfg\\yolov3.cfg\"\n",
    "names_path = r\"D:\\python\\python_INSTALL\\myenv\\darknet\\data\\coco.names\"\n",
    "\n",
    "# Ensure the paths exist\n",
    "if not (os.path.exists(weights_path) and os.path.exists(config_path) and os.path.exists(names_path)):\n",
    "    print(\"Error: One or more paths to YOLOv3 files are incorrect.\")\n",
    "    exit()\n",
    "\n",
    "# Load YOLOv3 configuration and weights\n",
    "net = cv2.dnn.readNet(weights_path, config_path)\n",
    "\n",
    "# Load the COCO class labels YOLO was trained on\n",
    "with open(names_path, \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Get the output layer names of the YOLO network\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Function to process a single frame\n",
    "def process_frame(frame):\n",
    "    height, width, channels = frame.shape\n",
    "\n",
    "    # Prepare the frame for YOLO\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    # Initialize variables for detected class IDs, confidences, and bounding boxes\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    # Process YOLO outputs\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5 and class_id == 2:  # 2 is the class ID for 'car' in COCO dataset\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    # Apply non-maxima suppression to filter overlapping boxes\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "    # Draw bounding boxes on the frame\n",
    "    car_count = 0\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            color = (0, 255, 0)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(frame, label, (x, y - 10), font, 1, color, 2)\n",
    "            car_count += 1\n",
    "\n",
    "    return frame, car_count\n",
    "\n",
    "# Access the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Webcam successfully opened.\")\n",
    "\n",
    "# Wait for the specified detection duration before starting detection\n",
    "print(f\"Waiting for {config.DETECTION_DURATION} seconds before starting detection...\")\n",
    "time.sleep(config.DETECTION_DURATION)\n",
    "\n",
    "start_time = time.time()  # Record the start time of the detection period\n",
    "detection_time = 5  # Time to detect cars after the waiting period\n",
    "end_time = start_time + detection_time  # Calculate the end time of the detection period\n",
    "\n",
    "total_car_count = 0  # Initialize total car count\n",
    "\n",
    "while True:\n",
    "    current_time = time.time()\n",
    "    elapsed_time = current_time - start_time\n",
    "\n",
    "    if elapsed_time > detection_time:\n",
    "        print(\"Detection period ended.\")\n",
    "        break\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame.\")\n",
    "        break\n",
    "\n",
    "    # Process the current frame\n",
    "    processed_frame, car_count = process_frame(frame)\n",
    "    total_car_count = car_count  # Update car count for the current frame\n",
    "\n",
    "    # Display the processed frame\n",
    "    cv2.imshow(\"Webcam\", processed_frame)\n",
    "\n",
    "    # Exit when 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "print(f\"Number of cars detected in the last {detection_time} seconds: {total_car_count}\")\n",
    "\n",
    "# Write the car count back to config.py\n",
    "with open('config.py', 'r') as file:\n",
    "    config_data = file.read()\n",
    "\n",
    "config_data = ast.literal_eval(config_data)\n",
    "\n",
    "# Update the car count\n",
    "config_data['CAR_COUNT'] = total_car_count\n",
    "\n",
    "# Write the updated data back to config.py\n",
    "with open('config.py', 'w') as file:\n",
    "    file.write(repr(config_data))\n",
    "\n",
    "# Release the webcam and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:131: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:131: SyntaxWarning: invalid escape sequence '\\w'\n",
      "C:\\Users\\GUNISH BAKSHI\\AppData\\Local\\Temp\\ipykernel_19696\\234287474.py:131: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  config_file.write(f'\"D:\\wooplix\\Traffic Project\\car_count.csv\"\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Webcam successfully opened.\n",
      "Waiting for 10 seconds before starting detection...\n",
      "Detection period ended.\n",
      "Number of cars detected in the last 30 seconds: 0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import config  # Import the config module\n",
    "\n",
    "# Paths to the YOLOv3 files\n",
    "weights_path = r\"D:\\python\\python_INSTALL\\myenv\\darknet\\src\\yolov3.weights\"\n",
    "config_path = r\"D:\\python\\python_INSTALL\\myenv\\darknet\\cfg\\yolov3.cfg\"\n",
    "names_path = r\"D:\\python\\python_INSTALL\\myenv\\darknet\\data\\coco.names\"\n",
    "\n",
    "# Ensure the paths exist\n",
    "if not (os.path.exists(weights_path) and os.path.exists(config_path) and os.path.exists(names_path)):\n",
    "    print(\"Error: One or more paths to YOLOv3 files are incorrect.\")\n",
    "    exit()\n",
    "\n",
    "# Load YOLOv3 configuration and weights\n",
    "net = cv2.dnn.readNet(weights_path, config_path)\n",
    "\n",
    "# Load the COCO class labels YOLO was trained on\n",
    "with open(names_path, \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Get the output layer names of the YOLO network\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Function to process a single frame\n",
    "def process_frame(frame):\n",
    "    height, width, channels = frame.shape\n",
    "\n",
    "    # Prepare the frame for YOLO\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    # Initialize variables for detected class IDs, confidences, and bounding boxes\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    # Process YOLO outputs\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5 and class_id == 2:  # 2 is the class ID for 'car' in COCO dataset\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    # Apply non-maxima suppression to filter overlapping boxes\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "    # Draw bounding boxes on the frame\n",
    "    car_count = 0\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            color = (0, 255, 0)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(frame, label, (x, y - 10), font, 1, color, 2)\n",
    "            car_count += 1\n",
    "\n",
    "    return frame, car_count\n",
    "\n",
    "# Access the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Webcam successfully opened.\")\n",
    "\n",
    "# Wait for the specified detection duration before starting detection\n",
    "print(f\"Waiting for {config.DETECTION_DURATION} seconds before starting detection...\")\n",
    "time.sleep(config.DETECTION_DURATION)\n",
    "\n",
    "start_time = time.time()  # Record the start time of the detection period\n",
    "detection_time = 30  # Time to detect cars after the waiting period\n",
    "end_time = start_time + detection_time  # Calculate the end time of the detection period\n",
    "\n",
    "total_car_count = 0  # Initialize total car count\n",
    "\n",
    "while True:\n",
    "    current_time = time.time()\n",
    "    elapsed_time = current_time - start_time\n",
    "\n",
    "    if elapsed_time > detection_time:\n",
    "        print(\"Detection period ended.\")\n",
    "        break\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame.\")\n",
    "        break\n",
    "\n",
    "    # Process the current frame\n",
    "    processed_frame, car_count = process_frame(frame)\n",
    "    total_car_count = car_count  # Update car count for the current frame\n",
    "\n",
    "    # Display the processed frame\n",
    "    cv2.imshow(\"Webcam\", processed_frame)\n",
    "\n",
    "    # Exit when 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "print(f\"Number of cars detected in the last {detection_time} seconds: {total_car_count}\")\n",
    "\n",
    "# Write the car count to a CSV file\n",
    "csv_file_path = 'car_count.csv'\n",
    "with open(csv_file_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Detection Duration (seconds)\", \"Car Count\"])\n",
    "    writer.writerow([detection_time, total_car_count])\n",
    "\n",
    "# Update the config.py file to store the path to the CSV file\n",
    "with open('config.py', 'a') as config_file:\n",
    "    config_file.write(f'\"D:\\wooplix\\Traffic Project\\car_count.csv\"\\n')\n",
    "\n",
    "# Release the webcam and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Webcam successfully opened.\n",
      "Waiting for 10 seconds before starting detection...\n",
      "Detection period ended.\n",
      "Number of cars detected in the last 30 seconds: 216\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import config  # Import the config module\n",
    "\n",
    "# Paths to the YOLOv3 files\n",
    "weights_path = r\"D:\\python\\python_INSTALL\\myenv\\darknet\\src\\yolov3.weights\"\n",
    "config_path = r\"D:\\python\\python_INSTALL\\myenv\\darknet\\cfg\\yolov3.cfg\"\n",
    "names_path = r\"D:\\python\\python_INSTALL\\myenv\\darknet\\data\\coco.names\"\n",
    "\n",
    "# Ensure the paths exist\n",
    "if not (os.path.exists(weights_path) and os.path.exists(config_path) and os.path.exists(names_path)):\n",
    "    print(\"Error: One or more paths to YOLOv3 files are incorrect.\")\n",
    "    exit()\n",
    "\n",
    "# Load YOLOv3 configuration and weights\n",
    "net = cv2.dnn.readNet(weights_path, config_path)\n",
    "\n",
    "# Load the COCO class labels YOLO was trained on\n",
    "with open(names_path, \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Get the output layer names of the YOLO network\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Function to process a single frame\n",
    "def process_frame(frame):\n",
    "    height, width, channels = frame.shape\n",
    "\n",
    "    # Prepare the frame for YOLO\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    # Initialize variables for detected class IDs, confidences, and bounding boxes\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    # Process YOLO outputs\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5 and class_id == 2:  # 2 is the class ID for 'car' in COCO dataset\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    # Apply non-maxima suppression to filter overlapping boxes\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "    # Draw bounding boxes on the frame\n",
    "    car_count = 0\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            color = (0, 255, 0)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(frame, label, (x, y - 10), font, 1, color, 2)\n",
    "            car_count += 1\n",
    "\n",
    "    return frame, car_count\n",
    "\n",
    "# Access the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Webcam successfully opened.\")\n",
    "\n",
    "# Wait for the specified detection duration before starting detection\n",
    "print(f\"Waiting for {config.DETECTION_DURATION} seconds before starting detection...\")\n",
    "time.sleep(config.DETECTION_DURATION)\n",
    "\n",
    "start_time = time.time()  # Record the start time of the detection period\n",
    "detection_time = 30  # Time to detect cars after the waiting period\n",
    "end_time = start_time + detection_time  # Calculate the end time of the detection period\n",
    "\n",
    "total_car_count = 0  # Initialize total car count\n",
    "\n",
    "while True:\n",
    "    current_time = time.time()\n",
    "    elapsed_time = current_time - start_time\n",
    "\n",
    "    if elapsed_time > detection_time:\n",
    "        print(\"Detection period ended.\")\n",
    "        break\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame.\")\n",
    "        break\n",
    "\n",
    "    # Process the current frame\n",
    "    processed_frame, car_count = process_frame(frame)\n",
    "    total_car_count += car_count  # Update car count for the current frame\n",
    "\n",
    "    # Display the processed frame\n",
    "    cv2.imshow(\"Webcam\", processed_frame)\n",
    "\n",
    "    # Exit when 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "print(f\"Number of cars detected in the last {detection_time} seconds: {total_car_count}\")\n",
    "\n",
    "# Write the car count to a CSV file (overwrite to keep only latest entries)\n",
    "csv_file_path = r'D:\\wooplix\\Traffic Project\\car_count.csv'  # Use a full path to avoid permission issues\n",
    "\n",
    "try:\n",
    "    with open(csv_file_path, mode='w', newline='') as file:  # Open in write mode to overwrite\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Detection Duration (seconds)\", \"Car Count\"])\n",
    "        writer.writerow([detection_time, total_car_count])\n",
    "except PermissionError as e:\n",
    "    print(f\"PermissionError: {e}. Please check if the file is open in another application or you have the necessary permissions.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while writing to the CSV file: {e}\")\n",
    "\n",
    "# Update the config.py file to store the path to the CSV file\n",
    "config_file_path = 'config.py'\n",
    "try:\n",
    "    with open(config_file_path, 'w') as config_file:  # Open in write mode to overwrite\n",
    "        config_file.write(f'\\nCSV_FILE_PATH = \"{csv_file_path}\"\\n')\n",
    "except PermissionError as e:\n",
    "    print(f\"PermissionError while updating config.py: {e}. Please check if you have the necessary permissions.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while updating config.py: {e}\")\n",
    "\n",
    "# Release the webcam and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
